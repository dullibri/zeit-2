}
# get last vintage (y.fin)
load(paste(DirCode,'/data/realtime_sets_cutoffday_31.RData',sep=''))
set=sets[[length(sets)]]
row.names(var.used)=gsub('-','\\.',row.names(var.used))
y.fin.col=grep(var.used[target,'code'],colnames(set))
y.fin=set[,y.fin.col,drop=F]
colnames(y.fin)=target
target.untr=paste(target,'untr',sep='-')
data[data$ym%in%row.names(y.fin),target.untr]=y.fin
# transform the data accordingly
data[,target]=target.t(data[,target.untr,drop=F],h)
# get vintage dates and target dates
row.n.vint=which(data$datE%in%gsub('-31','',names(sets)))
data[row.n.vint,'vint']=1
data[row.n.vint,'vint.num']=1:length(sets)
data[row.n.vint+h-plag,'set-target']=1:length(sets)
targetcol=grep(paste(target,'$',sep=''),colnames(data))
data$eval=is.na(data[,targetcol])==F&is.na(data$'set-target')==F
target.df=data[data$eval,c(target,'set-target')]
# loading results
# res.file=paste('H:/git/zeit-2/Results/IP_h',h,'_maxobs_',60+h,'.RData',sep='')
if (rec==1){
res.file=paste(DirCode,'/Results/rec_',target,'_h',h,'.RData',sep='')
}
if (rec==0&bicres!=0){
res.file=paste(DirCode,'/Results/aic',target,'_h',h,'.RData',sep='')
}
if (rec==0&bicres==1){
res.file=paste(DirCode,'/Results/',target,'_h',h,'.RData',sep='')
}
res.file
if (rec==0&bicres==0){
res.file=paste(DirCode,'/Results/aic',target,'_h',h,'.RData',sep='')
}
if (rec==0&bicres==1){
res.file=paste(DirCode,'/Results/',target,'_h',h,'.RData',sep='')
}
load(res.file)
DirCode='h:/Git/zeit-2'
# DirCode='C:/Users/Dirk/Documents/GitHub/zeit-2'
target='IP'
# target='CPI.EX'
max.hor=12
# wenn rec=1 und bicres=0 dann nur recursive, wenn rec=0 und bicres=1 dann mit aic
# wenn rec=0 und bicres=1 dann bic variante
# wenn post=1 nur post recession period
rec=0
bicres=0
plag=2 # publication lag
post=1 # nur post recession
library(stringr)
library(glmulti)
library(pracma)
library(MCS)
source(paste(DirCode,'/code/hansen_2005_test/f_Hansen_2005_Test_statistic.R',sep=''))
source(paste(DirCode,'/code/hansen_2005_test/f_Newey_West_bootstrapable.R',sep=''))
ni=4 # number of indicators in output
auxcodedir=paste(DirCode,'/code/auxiliary code',sep='')
source(paste(auxcodedir,'/lag.exact.R',sep=''))
source(paste(DirCode,'/Code/Clark_West_Test/f_Newey_West_vector.r',sep='') )
source(paste(DirCode,'/Code/Clark_West_Test/f_Clark_West_Test.r',sep=''))
source(paste(DirCode,'/Code/white_test/f_White_Reality_Check.r',sep='') )
# source(paste(DirCode,'/Code/white_test/Conduct_White_Test.r',sep='') )
source(paste(DirCode,'/Code/white_test/f_Politis_Romano_Bootstrap.R',sep='') )
source(paste(auxcodedir,'/olsself.R',sep=''))
source(paste(DirCode,'/Code/giacomini rossi/FB_Wald_CI.r',sep=''))
# creating aggregation matrix
firstyear=1990
lastyear=2015
nyear=lastyear-firstyear+1
cs=list()
mt=list()
rs=list()
cr=list()
white.p=list()
Hansen.pv=matrix(NA,nrow=max.hor,ncol=1)
WT.pv=matrix(NA,nrow=max.hor,ncol=1)
h=14
data=data.frame(m=rep(1:12,nyear)
,month=rep(c(paste(0,1:9,sep=''),paste(10:12)),nyear)
,year=rep(firstyear:lastyear,each=12))
data$ym=paste(data$year,data$month,sep='-')
data$datE=paste(data$year,data$m,sep='-')
# get ecri recession dates
ecri=read.csv(paste(DirCode,'/data/ecri/ecri.csv',sep=''),row.names=1)
row.names(ecri)=gsub('15/','',row.names(ecri))
t1=t(matrix(unlist(strsplit(row.names(ecri),'/')),nrow=2))
row.names(ecri)=apply(t1,1,function(x) paste(x[2],x[1],collapse='',sep='-'))
data[data$ym%in%row.names(ecri),'ecri']=ecri[,1]
# transformation function
target.t=function(y.raw,horizon){
y=1200/horizon*log(y.raw/lag.exact(y.raw,horizon))
}
# get last vintage (y.fin)
load(paste(DirCode,'/data/realtime_sets_cutoffday_31.RData',sep=''))
set=sets[[length(sets)]]
row.names(var.used)=gsub('-','\\.',row.names(var.used))
y.fin.col=grep(var.used[target,'code'],colnames(set))
y.fin=set[,y.fin.col,drop=F]
colnames(y.fin)=target
target.untr=paste(target,'untr',sep='-')
data[data$ym%in%row.names(y.fin),target.untr]=y.fin
# transform the data accordingly
data[,target]=target.t(data[,target.untr,drop=F],h)
# get vintage dates and target dates
row.n.vint=which(data$datE%in%gsub('-31','',names(sets)))
data[row.n.vint,'vint']=1
data[row.n.vint,'vint.num']=1:length(sets)
data[row.n.vint+h-plag,'set-target']=1:length(sets)
targetcol=grep(paste(target,'$',sep=''),colnames(data))
data$eval=is.na(data[,targetcol])==F&is.na(data$'set-target')==F
target.df=data[data$eval,c(target,'set-target')]
# loading results
# res.file=paste('H:/git/zeit-2/Results/IP_h',h,'_maxobs_',60+h,'.RData',sep='')
if (rec==1){
res.file=paste(DirCode,'/Results/rec_',target,'_h',h,'.RData',sep='')
}
if (rec==0&bicres==0){
res.file=paste(DirCode,'/Results/aic',target,'_h',h,'.RData',sep='')
}
if (rec==0&bicres==1){
res.file=paste(DirCode,'/Results/',target,'_h',h,'.RData',sep='')
}
load(res.file)
# forecasts
fc=sapply(forecast.all,function(x) as.numeric(x$fc))
modn=row.names(forecast.all[[1]])
# dropping vintages that can not be used
fc=fc[,1:nrow(target.df)]
row.names(fc)=modn
#         fc=fc[-grep('zeit|rword',row.names(fc)),]
# dimensions OK? dim(fc)
targetm=t(matrix(rep(target.df[,target],nrow(fc)),ncol=nrow(fc)))
fe=fc-targetm
# attaching dates to the errors
tdates=data[data$eval,'ym']
colnames(fe)=tdates
post
post=0
t=data(Loss)
library(MCS)
data(Loss)
View(Loss)
head(Loss)
Loss[,1:5]
tfe=t(fe)
tstfe=ts(fe,start=c(1900,1),freq=12)
MCS=MCSprocedure(Loss=tstfe,alpha=0.2,B=1000,statistic='Tmax',cl=NULL)
MCS=MCSprocedure(Loss=fe,alpha=0.2,B=1000,statistic='Tmax',cl=NULL)
MCS=MCSprocedure(Loss=fe[1:10,],alpha=0.2,B=1000,statistic='Tmax',cl=NULL)
MCS=MCSprocedure(Loss=fe[1:4,],alpha=0.2,B=1000,statistic='Tmax',cl=NULL)
MCS=MCSprocedure(Loss=fe[1:4,]^2,alpha=0.2,B=1000,statistic='Tmax',cl=NULL)
MCS=MCSprocedure(Loss=fe[1:4,]^2,alpha=0.01,B=1000,statistic='Tmax',cl=NULL)
MCS=MCSprocedure(Loss=Loss[,1:5],alpha=0.2,B=1000,statistic='Tmax',cl=NULL)
t=Loss[,1:5]
View(t)
MCS=MCSprocedure(Loss=t(fe[1:5,]^2),alpha=0.2,B=1000,statistic='Tmax',cl=NULL)
MCS=MCSprocedure(Loss=t(fe^2),alpha=0.2,B=1000,statistic='Tmax',cl=NULL)
MCS=MCSprocedure(Loss=t(fe[1:5,]^2),alpha=0.1,B=1000,statistic='Tmax',cl=NULL)
MCS=MCSprocedure(Loss=t(fe[1:15,]^2),alpha=0.1,B=1000,statistic='Tmax',cl=NULL)
View(fe)
MCS=MCSprocedure(Loss=t(fe^2),alpha=0.1,B=1000,statistic='Tmax',cl=NULL)
MCS
source('H:/git/zeit-2/code/mti experiment main code/evaluation_mcs.R', echo=TRUE)
source('H:/git/zeit-2/code/bewertung ZEIT/SentiWS_Zeit.R', echo=TRUE)
source('H:/git/zeit-2/code/bewertung ZEIT/SentiWS_Zeit.R', echo=TRUE)
sFolderTexte
pos=as.character(valueword['wert'>0,'wort',drop=T])
# pos=tolower(pos)
pos.w=valueword['wert'>0,'wert']
neg=as.character(valueword[valueword$wert<0,'wort',drop=T])
# neg=tolower(neg)
neg.w=valueword[valueword$wert<0,'wert']
pf=polarity_frame(pos,neg,pos.w,neg.w,env=F)
library("qdap", lib.loc="~/R/win-library/3.0")
pf=polarity_frame(pos,neg,pos.w,neg.w,env=F)
?polarity_frame
pf=polarity_frame(pos,neg,pos.w,neg.w)
valueword=read.csv(paste(DirCode,'/valueword.csv',sep=''))
pos=as.character(valueword['wert'>0,'wort',drop=T])
# pos=tolower(pos)
pos.w=valueword['wert'>0,'wert']
neg=as.character(valueword[valueword$wert<0,'wort',drop=T])
# neg=tolower(neg)
neg.w=valueword[valueword$wert<0,'wert']
pf=sentiment_frame(pos,neg,pos.w,neg.w)
# getting list of negative words
negating=read.csv(paste(DirCode,'/data/sentistrength_de/NegatingWordListueberarbeitet.txt',sep=''),header=F)
negating=negating[!negating=='']
negating=c(negating,c(''))
# splittet den text in sätzte auf und fügt $tot hinzu zur paragraph zuordnung
test=sentSplit(df,"Text")
tp=polarity(df$'Text',polarity.frame=pf,negators=negating)
pos=as.character(valueword['wert'>0,'wort',drop=T])
# pos=tolower(pos)
pos.w=valueword['wert'>0,'wert']
neg=as.character(valueword[valueword$wert<0,'wort',drop=T])
# neg=tolower(neg)
neg.w=valueword[valueword$wert<0,'wert']
pf=sentiment_frame(pos,neg,pos.w,neg.w)
View(pf)
negating=read.csv(paste(DirCode,'/data/sentistrength_de/NegatingWordListueberarbeitet.txt',sep=''),header=F)
View(negating)
negating=read.csv(paste(DirCode,'/data/sentistrength_de/NegatingWordListueberarbeitet.txt',sep=''),header=F)
negating=read.csv(paste(DirCode,'/data/sentistrength_de/NegatingWordListueberarbeitet.txt',sep=','),header=F)
negating=read.csv(paste(DirCode,'/data/sentistrength_de/NegatingWordListueberarbeitet.txt',sep=','),header=F)
DirCode
negating=read.csv(paste(DirCode,'/data/sentistrength_de/NegatingWordListueberarbeitet.txt',sep=''),sep=',',header=F)
View(negating)
?read.csv
negating=read.csv(paste(DirCode,'/data/sentistrength_de/negators',sep=''),header=F)
negating=read.csv(paste(DirCode,'/data/sentistrength_de/negators.csv',sep=''),header=F)
View(negating)
x
text
str(text)
test=sentSplit(text,"Text")
str(text)
?sentSplit
test=sentSplit(dataframe(c(person=dirk),text=text)
test=sentSplit(dataframe(c(person=dirk),text=text))
DATA
t=data.frame(text)
View(t)
test=sentSplit(t,'text')
View(test)
t=data.frame(text)
test=sentSplit(t,'text')
sentSplit(DATA, "state", stem.col = TRUE)
tp=polarity(text,polarity.frame=pf,negators=negating)
amplifiers
negating
?polarity
with(DATA, polarity(state, list(sex, adult)))
DATA
polarity(text)
tp=polarity(text,polarity.frame=pf)#,negators=negating)
tp
pf
pos.w
pos
text
strip=function (x, char.keep = "~~", digit.remove = TRUE, apostrophe.remove = TRUE,
lower.case = TRUE)
{
strp <- function(x, digit.remove, apostrophe.remove, char.keep,
lower.case) {
if (!is.null(char.keep)) {
x2 <- Trim(gsub(paste0(".*?($|'|", paste(paste0("\\",
char.keep), collapse = "|"), "|[^[:punct:]]).*?"),
"\\1", as.character(x)))
}
else {
x2 <- Trim(gsub(".*?($|'|[^[:punct:]]).*?", "\\1",
as.character(x)))
}
if (lower.case) {
x2 <- x2
}
if (apostrophe.remove) {
x2 <- gsub("'", "", x2)
}
ifelse(digit.remove == TRUE, gsub("[[:digit:]]", "",
x2), x2)
}
x <- clean(x)
unlist(lapply(x, function(x) Trim(strp(x = x, digit.remove = digit.remove,
apostrophe.remove = apostrophe.remove, char.keep = char.keep,
lower.case = lower.case))))
}
assignInNamespace('strip',strip,'qdap')
tp=polarity(text,polarity.frame=pf)#,negators=negating)
warnings()
tp
strip=function (x, char.keep = "~~", digit.remove = TRUE, apostrophe.remove = TRUE,
lower.case = F)
{
strp <- function(x, digit.remove, apostrophe.remove, char.keep,
lower.case) {
if (!is.null(char.keep)) {
x2 <- Trim(gsub(paste0(".*?($|'|", paste(paste0("\\",
char.keep), collapse = "|"), "|[^[:punct:]]).*?"),
"\\1", as.character(x)))
}
else {
x2 <- Trim(gsub(".*?($|'|[^[:punct:]]).*?", "\\1",
as.character(x)))
}
if (lower.case) {
x2 <- x2
}
if (apostrophe.remove) {
x2 <- gsub("'", "", x2)
}
ifelse(digit.remove == TRUE, gsub("[[:digit:]]", "",
x2), x2)
}
x <- clean(x)
unlist(lapply(x, function(x) Trim(strp(x = x, digit.remove = digit.remove,
apostrophe.remove = apostrophe.remove, char.keep = char.keep,
lower.case = lower.case))))
}
assignInNamespace('strip',strip,'qdap')
tp=polarity(text,polarity.frame=pf)#,negators=negating)
tp
tp[[1]]
text.s=text
text=gsub('\\\\','',text)
text
text=gsub('\\','',text)
text=gsub('\\\','',text)
text=gsub('\\\\','',text)
text=gsub('\\\\','',text)
text
Kennen Sie den Effekt Spricht man ein Wort nur oft genug aus beginnt es zunächst seine Bedeutung zu verlieren bis es schließlich völlig nichtssagend klingt Dann hat man den wahren Charakter des Wortes meist treffend herausgearbeitet Mild ist so ein Wort das wie Leser Erich P aus Berlin bemerkte ziemlich inhaltsleer ist Jedenfalls in Zusammenhang mit Joghurt Joghurt ist immer mild Es gibt praktisch keinen Joghurtbecher auf dem nicht mild steht Wahrscheinlich wirkt mild wie eine phonetische Kuscheldecke und schmeichelt der Seele des Konsumenten Harte Zeiten und wann waren sie je härter als heute verlangen schließlich nach mildernden Umständen zumindest aber nach mildernden Produkten Wie Joghurt Oder Kaffee Oder Käse Der Duden definiert mild als nicht stark gewürzt nicht scharf oder auch als nicht sehr kräftig Betriebswirtschaftlich ist das heikel Zwar spricht das Prädikat mild jene Zielgruppe an die Wert auf mild legt Zugleich aber schreckt es alle anderen ab Um potenzielle Kunden nicht zu vergraulen kombinieren Unternehmen deshalb mild gern mit seinen Gegensätzen Schwupps wird ein Cheddar Käse mild würzig Paprikas kommen als mild scharf daher und Kaffeesorten rühmen sich herzhaft mild oder mild kräftig zu sein Anzeige
text=c('Kennen Sie den Effekt Spricht man ein Wort nur oft genug aus beginnt es zunächst seine Bedeutung zu verlieren bis es schließlich völlig nichtssagend klingt Dann hat man den wahren Charakter des Wortes meist treffend herausgearbeitet Mild ist so ein Wort das wie Leser Erich P aus Berlin bemerkte ziemlich inhaltsleer ist Jedenfalls in Zusammenhang mit Joghurt Joghurt ist immer mild Es gibt praktisch keinen Joghurtbecher auf dem nicht mild steht Wahrscheinlich wirkt mild wie eine phonetische Kuscheldecke und schmeichelt der Seele des Konsumenten Harte Zeiten und wann waren sie je härter als heute verlangen schließlich nach mildernden Umständen zumindest aber nach mildernden Produkten Wie Joghurt Oder Kaffee Oder Käse Der Duden definiert mild als nicht stark gewürzt nicht scharf oder auch als nicht sehr kräftig Betriebswirtschaftlich ist das heikel Zwar spricht das Prädikat mild jene Zielgruppe an die Wert auf mild legt Zugleich aber schreckt es alle anderen ab Um potenzielle Kunden nicht zu vergraulen kombinieren Unternehmen deshalb mild gern mit seinen Gegensätzen Schwupps wird ein Cheddar Käse mild würzig Paprikas kommen als mild scharf daher und Kaffeesorten rühmen sich herzhaft mild oder mild kräftig zu sein Anzeige ')
tp=polarity(text,polarity.frame=pf)#,negators=negating)
tp
pos=as.character(valueword['wert'>0,'wort',drop=T])
# pos=tolower(pos)
pos.w=valueword['wert'>0,'wert']
neg=as.character(valueword[valueword$wert<0,'wort',drop=T])
# neg=tolower(neg)
neg.w=valueword[valueword$wert<0,'wert']
pf=polarity_frame(pos,neg,pos.w,neg.w)
pf=sentiment_frame(pos,neg,pos.w,neg.w)
View(pf)
negating=read.csv(paste(DirCode,'/data/sentistrength_de/negators.csv',sep=''),header=F)
View(negating)
negating=read.csv(paste(DirCode,'/data/sentistrength_de/negators.csv',sep=''),header=F)
tp=polarity(text,polarity.frame=pf,negators=negating)
negating=as.vector(negating)
negating=unlist(negating)
?read.csv
negating=read.csv(paste(DirCode,'/data/sentistrength_de/negators.csv',sep=''),header=F,stringsAsFactors=F)
negating=unlist(negating)
negating
tp=polarity(text,polarity.frame=pf,negators=negating)
tp
warnings
warnings()
if (length(text) == 2 & text[1] == ",x") {
text = text[2]
}
text.split = sapply(strsplit(text, " "), function(x) x)
ind = valueword[, 1] %in% text.split
valdf = valueword[ind, , drop = F]
valdf$h = sapply(valueword[ind, 1], function(x) sum(text.split %in%
x))
nwords = length(text.split)
valdf
ind
ind.rev=text.split%in% valueword[, 1]
ind.rev
grep('\\.',text)
text.split
text
text<-readLines(paste(sFolderTexte,svFile[i],sep=''), encoding="UTF-8")#, header=T,stringsAsFactors =F)
text
strip=function (x, char.keep = "~~", digit.remove = TRUE, apostrophe.remove = TRUE,
lower.case = FALSE)
{
strp <- function(x, digit.remove, apostrophe.remove, char.keep,
lower.case) {
if (!is.null(char.keep)) {
x2 <- Trim(gsub(paste0(".*?($|'|", paste(paste0("\\",
char.keep), collapse = "|"), "|[^[:punct:]]).*?"),
"\\1", as.character(x)))
}
else {
x2 <- Trim(gsub(".*?($|'|[^[:punct:]]).*?", "\\1",
as.character(x)))
}
if (lower.case) {
x2 <- x2
}
if (apostrophe.remove) {
x2 <- gsub("'", "", x2)
}
ifelse(digit.remove == TRUE, gsub("[[:digit:]]", "",
x2), x2)
}
x <- clean(x)
unlist(lapply(x, function(x) Trim(strp(x = x, digit.remove = digit.remove,
apostrophe.remove = apostrophe.remove, char.keep = char.keep,
lower.case = lower.case))))
}
assignInNamespace('strip',strip,'qdap')
strip
tp=polarity(text,polarity.frame=pf,negators=negating)
tpa=tp$all
tpa
if (length(text) == 2 & text[1] == ",x") {
text = text[2]
}
text.split = sapply(strsplit(text, " "), function(x) x)
grep('\\.',text)
ind = valueword[, 1] %in% text.split
#         ind.rev=text.split%in% valueword[, 1]
valdf = valueword[ind, , drop = F]
valdf$h = sapply(valueword[ind, 1], function(x) sum(text.split %in%
x))
nwords = length(text.split)
valdf
sum(valdf$wert)
ind.neg=text.split%in% negating
ind.neg
tpa
tpa[[1]]
tpa[1]
tpa$wc
tpa$polarity
tpa=tp$all[c('wc','polarity')]
tpa
sent=tp$all[c('polarity')]
nwords<-tp$all[c('wc')]
nwords
paste(DirCode,'Ergebnis_qdap_negator',jj,'_',k,'.csv',sep='')
paste(DirCode,'/data/zeit indikatoren/Ergebnis_qdap_negator',jj,'_',k,'.csv',sep='')
source('H:/git/zeit-2/code/bewertung ZEIT/SentiWS_Zeit_qdap.R', echo=TRUE)
colnames(Ergebnis)=c('id','value','nword')
source('H:/git/zeit-2/code/bewertung ZEIT/SentiWS_Zeit_qdap.R', echo=TRUE)
paste(DirCode,'/data/zeit indikatoren/Ergebnis_qdap_negator_',jj,'_',k,'.csv',sep='')
k=1
sFolderTexte=paste(DirRawTexts,'/',liste_jahr[k],'/',sep='')
print(sFolderTexte)
# getting list and number of articles
svFile=list.files(sFolderTexte)
svFile=svFile[grep('article',svFile)]
Narticle_issue=length(svFile)
Ergebnis=data.frame(matrix(NA,1,3))
colnames(Ergebnis)=c('id','value','nword')
i=11
text<-readLines(paste(sFolderTexte,svFile[i],sep=''), encoding="UTF-8")#, header=T,stringsAsFactors =F)
paste(sFolderTexte,svFile[i],sep='')
?readLines
text<-readLines(paste(sFolderTexte,svFile[i],OK=F,sep=''), encoding="UTF-8")#, header=T,stringsAsFactors =F)
text<-readLines(paste(sFolderTexte,svFile[i],sep=''), OK=F,encoding="UTF-8")#, header=T,stringsAsFactors =F)
text<-readLines(paste(sFolderTexte,svFile[i],sep=''), ok=F,encoding="UTF-8")#, header=T,stringsAsFactors =F)
paste(sFolderTexte,svFile[i],sep='')
text=read.csv(paste(sFolderTexte,svFile[i],sep=''),stringsAsFactors=F)
View(text)
text=read.csv(paste(sFolderTexte,svFile[i],sep=''),stringsAsFactors=F,header=F)
View(text)
?read.csv
text=read.csv(paste(sFolderTexte,svFile[i],sep=''),stringsAsFactors=F,header=F)
View(text)
str(text)
text=text[2]
text
if (nobs(text)>1){
text=text[2]
}
if (length(text)>1){
text=text[2]
}
(length(text)>1)
if (nchar(text)>1){
text=text[2]
}
?nchar
nchar(text)
length(text)
nrow(text)
if (nrow(text)>1){
text=text[2]
}
text=text[2,1]
source.with.encoding('~/.active-rstudio-document', encoding='UTF-8', echo=TRUE)
source.with.encoding('~/.active-rstudio-document', encoding='UTF-8', echo=TRUE)
View(text)
if (nrow(text)>1)
(nrow(text)>1)
source.with.encoding('~/.active-rstudio-document', encoding='UTF-8', echo=TRUE)
source.with.encoding('~/.active-rstudio-document', encoding='UTF-8', echo=TRUE)
text
text=read.csv(paste(sFolderTexte,svFile[i],sep=''),stringsAsFactors=F,header=F)
View(text)
is.character(text)
text
str(text)
View(text)
sapply(text,is.char(x))
sapply(text,is.character(x))
sapply(text,is.character())
sapply(text,function(x) is.character(x))
text=read.csv(paste(sFolderTexte,svFile[i],sep=''),stringsAsFactors=F,header=F)
text=read.table(paste(sFolderTexte,svFile[i],sep=''),stringsAsFactors=F,header=F,row.names=F,col.names=F)
text=read.table(paste(sFolderTexte,svFile[i],sep=''),row.names=F,col.names=F)
text<-readLines(paste(sFolderTexte,svFile[i],sep=''), ok=F,encoding="UTF-8")#, header=T,stringsAsFactors =F)
text=read.csv(paste(sFolderTexte,svFile[i],sep=''),stringsAsFactors=F,header=F)
str(text)
t=sapply(text,function(x) is.character(x))
chrtest=sapply(text,function(x) is.character(x))
chrtest
text=text[,chrtest]
which(text=='x')
text=paste(text[,chrtest],collapse='')
text=paste(text[,chrtest],collapse='',sep='')
text=paste(text[,chrtest],collapse=' ',sep='')
text=paste(text,collapse=' ',sep='')
text=paste(text,collapse=' ',sep='')
source.with.encoding('~/.active-rstudio-document', encoding='UTF-8', echo=TRUE)
jj
k
source.with.encoding('~/.active-rstudio-document', encoding='UTF-8', echo=TRUE)
k
for (jj in 1990)#:2015){#jj=2015
source.with.encoding('~/.active-rstudio-document', encoding='UTF-8', echo=TRUE)
source.with.encoding('~/.active-rstudio-document', encoding='UTF-8', echo=TRUE)
source.with.encoding('~/.active-rstudio-document', encoding='UTF-8', echo=TRUE)
