, header=F)
Pos=pos.words[pos.words[,2]=='NN',]
pos=pos.words[pos.words[,2]!='NN',]
NEG=matrix(NA,nrow=nrow(neg.words),ncol=1)
for (i in 1:nrow(neg.words)){NEG[i,]=paste(neg.words[i,1],neg.words[i,4],sep=',')}
NEG=data.frame(value=neg.words[,3],words=as.character(NEG))
Neg=NEG[neg.words[,2]=='NN',]
neg=NEG[neg.words[,2]!='NN',]
POS=matrix(NA,nrow=nrow(pos.words),ncol=1)
for (i in 1:nrow(pos.words)){POS[i,]=paste(pos.words[i,1],pos.words[i,4],sep=',')}
POS=data.frame(value=pos.words[,3],words=as.character(POS))
Pos=POS[pos.words[,2]=='NN',]
pos=POS[pos.words[,2]!='NN',]
# remove double entries
doppelraus=function(x){
x=as.character(x)
x=strsplit(x,',')
x=unique(x)
x=sapply(x,function(x) x)
x=paste(x,',',collapse='')
}
pos[,2]=sapply(pos[,2],doppelraus)
Pos[,2]=sapply(Pos[,2],doppelraus)
neg[,2]=sapply(neg[,2],doppelraus)
Neg[,2]=sapply(Neg[,2],doppelraus)
pos[2,2]
class(pos[2,2])
tt=gsub(' ','',x)
class(tt)
tt
doppelraus=function(x){
x=as.character(x)
x=strsplit(x,',')
x=unique(x)
x=sapply(x,function(x) x)
x=paste(x,',',collapse='')
x=gsub(' ','',x)
}
pos[,2]=sapply(pos[,2],doppelraus)
Pos[,2]=sapply(Pos[,2],doppelraus)
neg[,2]=sapply(neg[,2],doppelraus)
Neg[,2]=sapply(Neg[,2],doppelraus)
pos[2,2]
pool=c(paste(pos[,2],','),paste(neg[,2],','))
pool=paste(pool,sep='',collapse='')
str(pool)
pool=c(paste(pos[,2],','),paste(neg[,2],','))
pool=paste(pool,sep='',collapse='')
pool=strsplit(pool,',')
pool=c(paste(pos[,2],','),paste(neg[,2],','))
pool=paste(pool,sep='',collapse='')
pool=sapply(strsplit(pool,','),function(x)x)
View(pool)
dpool=duplicated(pool)
dpool
pool[dpool]
dupli=pool[dpool]
dupli=dupli[dupli!=' ']
dupli
duplind=function(x){
c(grep(x,pos[,2]),grep(x,neg[,2]))
}
test=sapply(dupli,duplind)
neg[148,]
neg[149,]
pos[49,]
dupli[1]
grep('ausgezeichnet',pos[,2])
pos[73]
pos[73,]
pos[81,]
grep('ausgezeichnet',neg[,2])
pos[148,]
sapply(strsplit(pos[148,],','),function(x))
sapply(strsplit(pos[148,],','),function(x)x)
sapply(strsplit(pos[148,],','),function(x) x)
sapply(strsplit(pos[148,2],','),function(x) x)
sapply(strsplit(pos[149,2],','),function(x) x)
pos[149,]
pos[148,]
pos[49,]
?duplicated
?unique
test=match(dupli,pool)
test
pool[test]
match('bessere',pool)
pool[1905]
match('bessern',pool)
match('besseren',pool)
dupli
duplind=function(x){
t=c(grep(x,pos[,2]),grep(x,neg[,2]))
}
duplind(dupli[1])
duplind=function(x){
t=c(grep(x,pos[,2]),grep(x,neg[,2]))
return(t)
}
duplind(dupli[1])
duplind=function(x){
p=grep(x,pos[,2])
n=grep(x,neg[,2])
return(p,n)
}
duplind(dupli[1])
duplind=function(x){
p=grep(x,pos[,2])
n=grep(x,neg[,2])
return(list(p,n))
}
duplind(dupli[1])
pos[c(73,81),]
p=grep(x,pos[,2])
x=dupli[1]
p=grep(x,pos[,2])
p
pos[p,]
length(unique(pos[p,1]))==1
x=dupli[2]
p=grep(x,pos[,2])
pos[p,1]
length(unique(pos[p,1]))==1
n=grep(x,neg[,2])
neg[n,1]
n
x=dupli[3]
p=grep(x,pos[,2])
pos[p,1]
x
x=dupli[10]
p=grep(x,pos[,2])
pos[p,1]
pos[p,]
posneg=rbind(pos,neg)
pool=paste(posneg,sep='',collapse='')
pool=sapply(strsplit(pool,','),function(x)x)
dpool=duplicated(pool)
dupli=pool[dpool]
dupli
pool
pool=paste(posneg,sep='',collapse=' ')
pool=sapply(strsplit(pool,','),function(x)x)
pool
pool=paste(posneg,sep=' ',collapse=' ')
pool=sapply(strsplit(pool,','),function(x)x)
pool
pool=gsub('\\\\','',pool)
pool=gsub('\\\\n\\\\','',pool)
pool
pool=gsub('\n\','',pool)
pool=gsub('\n\\\\\','',pool)
pool=gsub('\n\\\\\','',pool)
pool=paste(posneg,sep=' ',collapse=' ')
pool=paste(posneg,sep=' ',collapse=' ')
pool
posneg
pool=paste(posneg[,2],sep=' ',collapse=' ')
pool=sapply(strsplit(pool,','),function(x)x)
pool
pool=gsub(' ','',pool)
pool
dpool=duplicated(pool)
dupli=pool[dpool]
dupli
for (i in dupli){pool=gsub(i,'',pool)}
for (i in dupli){pool=gsub(i,'',posneg[,2])}
View(posneg)
POSNEG=rbind(POS,NEG)
pool=paste(POSNEG[,2],sep=' ',collapse=' ')
pool=sapply(strsplit(pool,','),function(x)x)
pool=gsub(' ','',pool)
dpool=duplicated(pool)
dupli=pool[dpool]
dupli
for (i in dupli){pool=gsub(i,'',POSNEG[,2])} # 121 terms of 28621
pool=paste(posneg[,2],sep=' ',collapse=' ')
pool=sapply(strsplit(pool,','),function(x)x)
pool=gsub(' ','',pool)
dpool=duplicated(pool)
dupli=pool[dpool]
test=ls()
test
test[test!='POSNEG'|test!='posneg']
del=ls()
del(-grep('POSNEG',del))
del=ls()
del
del(-grep('POSNEG',del))
grep('POSNEG',del)
c(grep('POSNEG',del),grep('posneg',del))
del=del[-c(grep('POSNEG',del),grep('posneg',del))]
del
rm(list=del)
View(POSNEG)
View(posneg)
# Loads SentiWS and splits it up in positive/negative, lower/uppercase words ----------------------------
sDirS='/SentiWS_v1.8c/'
# located in DirCode
pos.words <- read.delim(paste(DirCode,sDirS,"SentiWS_v1.8c_Positive_without_pipes.txt",sep='')# pipes have been eliminated with excel.
, encoding="UTF-8"
, header=F)
neg.words <- read.delim(paste(DirCode,sDirS,"SentiWS_v1.8c_Negative_without_pipes.txt",sep='')
, encoding="UTF-8"
, header=F)
Pos=pos.words[pos.words[,2]=='NN',]
pos=pos.words[pos.words[,2]!='NN',]
NEG=matrix(NA,nrow=nrow(neg.words),ncol=1)
for (i in 1:nrow(neg.words)){NEG[i,]=paste(neg.words[i,1],neg.words[i,4],sep=',')}
NEG=data.frame(value=neg.words[,3],words=as.character(NEG))
Neg=NEG[neg.words[,2]=='NN',]
neg=NEG[neg.words[,2]!='NN',]
POS=matrix(NA,nrow=nrow(pos.words),ncol=1)
for (i in 1:nrow(pos.words)){POS[i,]=paste(pos.words[i,1],pos.words[i,4],sep=',')}
POS=data.frame(value=pos.words[,3],words=as.character(POS))
Pos=POS[pos.words[,2]=='NN',]
pos=POS[pos.words[,2]!='NN',]
# remove double entries
doppelraus=function(x){
x=as.character(x)
x=strsplit(x,',')
x=unique(x)
x=sapply(x,function(x) x)
x=paste(x,',',collapse='')
x=gsub(' ','',x)
}
pos[,2]=sapply(pos[,2],doppelraus)
Pos[,2]=sapply(Pos[,2],doppelraus)
neg[,2]=sapply(neg[,2],doppelraus)
Neg[,2]=sapply(Neg[,2],doppelraus)
posneg=rbind(pos,neg)
POSNEG=rbind(Pos,Neg)
# Loads SentiWS and splits it up in positive/negative, lower/uppercase words ----------------------------
sDirS='/SentiWS_v1.8c/'
# located in DirCode
pos.words <- read.delim(paste(DirCode,sDirS,"SentiWS_v1.8c_Positive_without_pipes.txt",sep='')# pipes have been eliminated with excel.
, encoding="UTF-8"
, header=F)
neg.words <- read.delim(paste(DirCode,sDirS,"SentiWS_v1.8c_Negative_without_pipes.txt",sep='')
, encoding="UTF-8"
, header=F)
Pos=pos.words[pos.words[,2]=='NN',]
pos=pos.words[pos.words[,2]!='NN',]
NEG=matrix(NA,nrow=nrow(neg.words),ncol=1)
for (i in 1:nrow(neg.words)){NEG[i,]=paste(neg.words[i,1],neg.words[i,4],sep=',')}
NEG=data.frame(value=neg.words[,3],words=as.character(NEG))
Neg=NEG[neg.words[,2]=='NN',]
neg=NEG[neg.words[,2]!='NN',]
POS=matrix(NA,nrow=nrow(pos.words),ncol=1)
for (i in 1:nrow(pos.words)){POS[i,]=paste(pos.words[i,1],pos.words[i,4],sep=',')}
POS=data.frame(value=pos.words[,3],words=as.character(POS))
Pos=POS[pos.words[,2]=='NN',]
pos=POS[pos.words[,2]!='NN',]
pos.words <- read.delim(paste(DirCode,sDirS,"SentiWS_v1.8c_Positive_without_pipes.txt",sep='')# pipes have been eliminated with excel.
, encoding="UTF-8"
, header=F)
DirCode='H:/git/zeit-2'
# Loads SentiWS and splits it up in positive/negative, lower/uppercase words ----------------------------
sDirS='/SentiWS_v1.8c/'
# located in DirCode
pos.words <- read.delim(paste(DirCode,sDirS,"SentiWS_v1.8c_Positive_without_pipes.txt",sep='')# pipes have been eliminated with excel.
, encoding="UTF-8"
, header=F)
neg.words <- read.delim(paste(DirCode,sDirS,"SentiWS_v1.8c_Negative_without_pipes.txt",sep='')
, encoding="UTF-8"
, header=F)
Pos=pos.words[pos.words[,2]=='NN',]
pos=pos.words[pos.words[,2]!='NN',]
NEG=matrix(NA,nrow=nrow(neg.words),ncol=1)
for (i in 1:nrow(neg.words)){NEG[i,]=paste(neg.words[i,1],neg.words[i,4],sep=',')}
NEG=data.frame(value=neg.words[,3],words=as.character(NEG))
Neg=NEG[neg.words[,2]=='NN',]
neg=NEG[neg.words[,2]!='NN',]
POS=matrix(NA,nrow=nrow(pos.words),ncol=1)
for (i in 1:nrow(pos.words)){POS[i,]=paste(pos.words[i,1],pos.words[i,4],sep=',')}
POS=data.frame(value=pos.words[,3],words=as.character(POS))
Pos=POS[pos.words[,2]=='NN',]
pos=POS[pos.words[,2]!='NN',]
# remove double entries
doppelraus=function(x){
x=as.character(x)
x=strsplit(x,',')
x=unique(x)
x=sapply(x,function(x) x)
x=paste(x,',',collapse='')
x=gsub(' ','',x)
}
pos[,2]=sapply(pos[,2],doppelraus)
Pos[,2]=sapply(Pos[,2],doppelraus)
neg[,2]=sapply(neg[,2],doppelraus)
Neg[,2]=sapply(Neg[,2],doppelraus)
posneg=rbind(pos,neg)
POSNEG=rbind(Pos,Neg)
pool=paste(posneg[,2],sep=' ',collapse=' ')
pool=sapply(strsplit(pool,','),function(x)x)
pool=gsub(' ','',pool)
dpool=duplicated(pool)
dupli=pool[dpool]
for (i in dupli){pool=gsub(i,'',posneg[,2])} # 197 terms of 28419 eliminated
pool=paste(POSNEG[,2],sep=' ',collapse=' ')
pool=sapply(strsplit(pool,','),function(x)x)
pool=gsub(' ','',pool)
dpool=duplicated(pool)
dupli=pool[dpool]
for (i in dupli){pool=gsub(i,'',POSNEG[,2])} # 2 terms of 2862 eliminated
dupli
del=ls()
del=del[-c(grep('POSNEG',del),grep('posneg',del))]
rm(list=del)
rm(del)
View(POSNEG)
source('H:/git/zeit-2/Preparing SentiWs.R', echo=TRUE)
View(POSNEG)
View(posneg)
POSNEG[1,2]=gsub('<U+FEFF>','',POSNEG[1,2])
View(POSNEG)
POSNEG[1,2]='Abmachung,Abmachungen,'
View(POSNEG)
gross=function(x){x=grep('([A-ZÖÄÜ][a-zäüöß]+)',x)} # returns a vector of the uppercase words in a char vector
DirCode='H:/git/zeit-2'
setwd(DirCode)
load(paste(DirCode,"/register.RData",sep=''))
DirRawTexts="H:/Zeit"
library(tm)
gross=function(x){x=grep('([A-ZÖÄÜ][a-zäüöß]+)',x)} # returns a vector of the uppercase words in a char vector
# Setting directories for storing files -------------------------------------------------------
DirRawTexts="H:/Zeit" # text files are stored here
DirCode='H:/git/zeit-2' # main directory
setwd(DirCode)
# Load register created by 'Getting_register.R' ---------------------------
load(paste(DirCode,"/register.RData",sep=''))
# Getting subdirectories --------------------------------------------------
listsubdirs=list.files(DirRawTexts)
# Beschreibung ------------------------------------------------------------
# dieser code liest zeit-artikel ein und bewertet sie anhand von SentiWS.
# 1. die anzahl der positiven und negativen Worten wird mit den Bewertungszahlen gewichtet und
#    aufsummiert
# 2. die anzahl der positiven und negativen worte wird berechnet
# 3. die bewertung auf positiv und negativ aufgesplittet wird angegeben.
# Letzte Modifikation -------------------------------------------------------------------
# 2014-12-01, 17:08
# 2014-11-25, 17:14
# 2014-06-20, 22:22
# Load the necessary libraries and defining functions
library(tm)
gross=function(x){x=grep('([A-ZÖÄÜ][a-zäüöß]+)',x)} # returns a vector of the uppercase words in a char vector
# Setting directories for storing files -------------------------------------------------------
DirRawTexts="H:/Zeit" # text files are stored here
DirCode='H:/git/zeit-2' # main directory
setwd(DirCode)
# Load register created by 'Getting_register.R' ---------------------------
load(paste(DirCode,"/register.RData",sep=''))
# Getting subdirectories --------------------------------------------------
listsubdirs=list.files(DirRawTexts)
#  SentiWS: ------------------------------------------------------------------------
#       getting the list of positive and negative words and their values -----------------------------------------------------------------
#       posneg (lowercase) POSNEG (uppercase)
source('Preparing SentiWs.R')
save.image("H:/git/zeit-2/SentiWS.RData")
# Beschreibung ------------------------------------------------------------
# dieser code liest zeit-artikel ein und bewertet sie anhand von SentiWS.
# 1. die anzahl der positiven und negativen Worten wird mit den Bewertungszahlen gewichtet und
#    aufsummiert
# 2. die anzahl der positiven und negativen worte wird berechnet
# 3. die bewertung auf positiv und negativ aufgesplittet wird angegeben.
# Letzte Modifikation -------------------------------------------------------------------
# 2014-12-01, 17:08
# 2014-11-25, 17:14
# 2014-06-20, 22:22
# Load the necessary libraries and defining functions
library(tm)
gross=function(x){x=grep('([A-ZÖÄÜ][a-zäüöß]+)',x)} # returns a vector of the uppercase words in a char vector
# Setting directories for storing files -------------------------------------------------------
DirRawTexts="H:/Zeit" # text files are stored here
DirCode='H:/git/zeit-2' # main directory
setwd(DirCode)
# Load register created by 'Getting_register.R' ---------------------------
load(paste(DirCode,"/register.RData",sep=''))
# Getting subdirectories --------------------------------------------------
listsubdirs=list.files(DirRawTexts)
#  SentiWS: ------------------------------------------------------------------------
#       getting the list of positive and negative words and their values -----------------------------------------------------------------
#       posneg (lowercase) POSNEG (uppercase)
# source('Preparing SentiWs.R')
load(paste(DirCode,"/SentiWS.RData",sep=''))
jj=1990
liste_jahr=listsubdirs[grep(as.character(1990),listsubdirs)]
liste_jahr
k=1
sFolderTexte=paste(DirRawTexts,'/',liste_jahr[k],'/',sep='')
svFile=list.files(sFolderTexte)
svFile=svFile[grep('article',svFile)]
Narticle_issue=length(svFile)
rohtext=character(Narticle_issue) # upper case words of the respective texts
Rohtext=character(Narticle_issue) # lower case words
for (i in 1:Narticle_issue){#)
aux<-readLines(paste(sFolderTexte,svFile[i],sep=''), encoding="UTF-8")#, header=T,stringsAsFactors =F)
if (length(aux)>1&nchar(aux[1])<5){aux=aux[2]}
# This splits rohtext[1] into lower- (roh) and uppercase (Roh) words
aux_split=strsplit(aux,' ')
Roh_ind=sapply(aux_split,gross)
roh_ind=c(1:length(aux_split[[1]]))[-Roh_ind]
rohtext[i]=paste(sapply(roh_ind,function(x) aux_split[[1]][x] )
,collapse=' '
,sep=' ')
Rohtext[i]=paste(sapply(Roh_ind,function(x) aux_split[[1]][x])
,collapse=' '
,sep=' ')
}
rm(i)
docs <- Corpus(VectorSource(rohtext), readerControl = list(language = "De"))
# docs <- tm_map(docs, tolower) # does not matter, as document term matrix will eliminate capital letters
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removePunctuation,preserve_intra_word_dashes = T)
docs <- tm_map(docs, removeWords, stopwords("german"))
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, removeWords, c("</p>","/","@","\\|"))
# docs <- tm_map(docs,stemDocument) # there are most permutations listed, which makes discerning between different
# parts of
DOCS <- Corpus(VectorSource(Rohtext), readerControl = list(language = "De"))
# docs <- tm_map(docs, tolower) # does not matter, as document term matrix will eliminate capital letters
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removePunctuation,preserve_intra_word_dashes = T)
docs <- tm_map(docs, removeWords, stopwords("german"))
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, removeWords, c("</p>","/","@","\\|"))
# Which influence has not taking account of capital letters ---------------
#     VORHER MUSS tolower(POSNEG,posneg.words) abgestellt werden
# test <-tolower(POSNE
inspect(DOCS[1])
docs <- Corpus(VectorSource(rohtext), readerControl = list(language = "De"))
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removePunctuation,preserve_intra_word_dashes = T)
docs <- tm_map(docs, removeWords, stopwords("german"))
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, removeWords, c("</p>","/","@","\\|"))
# docs <- tm_map(docs,stemDocument) # there are most permutations listed, which makes discerning between different
# parts of speech easier.
DOCS <- Corpus(VectorSource(Rohtext), readerControl = list(language = "De"))
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removePunctuation,preserve_intra_word_dashes = T)
docs <- tm_map(docs, removeWords, stopwords("german"))
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, removeWords, c("</p>","/","@","\\|"))
# Which influence has not taking account of capital letters ---------------
inspect(DOCS[1])
DOCS <- tm_map(DOCS, tolower)
DOCS <- tm_map(DOCS, removeNumbers)
DOCS <- tm_map(DOCS, removePunctuation,preserve_intra_word_dashes = T)
DOCS <- tm_map(DOCS, removeWords, stopwords("german"))
DOCS <- tm_map(DOCS, stripWhitespace)
DOCS <- tm_map(DOCS, removeWords, c("</p>","/","@","\\|"))
# Which
inspect(DOCS[1])
dtm <- DocumentTermMatrix(docs)
Mdtm=as.matrix(dtm)
# Welche reihennummer haben in POSNEG haben die relevanten spalten in der dtm ---------------------------------
t9=match(colnames(dtm),posneg)
Mdtm_rel=Mdtm[,is.na(t9)==F]
Mdtm_rel
rel_words=as.matrix(colnames(Mdtm_rel))
Mdtm
posneg
t9=match(colnames(dtm),posneg[,2])
t9
Mdtm_rel=Mdtm[,is.na(t9)==F]
Mdtm_rel
colnames(dtm)
test=posneg[,2]
test=paste(posneg[,2],collapse='',sep='')
test=sapply(strsplit(test,','),function x)
test=sapply(strsplit(test,','),function(x) x)
t9=match(colnames(dtm),test)
Mdtm_rel=Mdtm[,is.na(t9)==F]
rel_words=as.matrix(colnames(Mdtm_rel))
rel_words
test=match(posneg,rel_words) # die existierenden werte sind die zeilennummern von rel_words
tt=test[is.na(test)==F]
t1=c(1:length(posneg))[is.na(test)==F] #  das sind die dazugehörigen spaltennumern von POSNEG
t2=data.frame(zeile_von_Mdtm_rel_in_posneg=test[t1],zeile_posneg=t1) # die beiden zu einem dataframe
t2=t2[with(t2,order(zeile_von_Mdtm_rel_in_posneg)),] # nach spaltennummern er Mdtm_rel, d.h. rel_words zeilennummern sortieren
t2
t1
tt
test
vposneg=paste(posneg[,2],collapse='',sep='')
vposneg=sapply(strsplit(vposneg,','),function(x) x)
t9=match(colnames(dtm),vposneg[,2])
t9=match(colnames(dtm),vposneg)
Mdtm_rel=Mdtm[,is.na(t9)==F]
rel_words=as.matrix(colnames(Mdtm_rel))
# spalten-worte den POSNEG zuordnen ---------------------------------------
test=match(vposneg,rel_words) # die existierenden werte sind die zeilennummern von rel_words
test
tt=test[is.na(test)==F]
tt
t1=c(1:length(vposneg))[is.na(test)==F] #  das sind die dazugehörigen spaltennumern von POSNEG
t1
t2=data.frame(zeile_von_Mdtm_rel_in_posneg=test[t1],zeile_posneg=t1) # die beiden zu einem dataframe
t2=t2[with(t2,order(zeile_von_Mdtm_rel_in_posneg)),] # nach spaltennummern er Mdtm_rel, d.h. rel_words zeilennummern sortieren
t2
Mdtm_rel
View(Mdtm)
View(Mdtm_rel)
t3=apply(Mdtm_rel,1,function(x,y){x*y},y=posneg.words[t2[,2],3]) # anzahl rel_words X anzahl artikel
t3=apply(Mdtm_rel,1,function(x,y){x*y},y=posneg.words[t2[,1],3]) # anzahl rel_words X anzahl artikel
t3=apply(Mdtm_rel,1,function(x,y){x*y},y=posneg[t2[,1],3]) # anzahl rel_words X anzahl artikel
posneg[t2[,1],1]
s
1
