"","x"
"1","Rettet die Wissenschaft!: Signifikanter UnsinnViele Forscher haben Probleme mit den Grundbegriffen der Statistik. vonÂ Christoph DrÃ¶sser											DIE ZEIT NÂº 01/2014 3. Januar 2014Â 									18:10 UhrÂ 							64 KommentareBeachten Sie die Anmerkung des Autors am Ende des Artikels!Signifikanz â das ist das Siegel, das ein naturwissenschaftliches Paper      braucht, um glaubwÃ¼rdig zu sein. Liefert ein Experiment ein signifikantes Ergebnis, dann wird      daraus hÃ¤ufig geschlossen, dass die hinter der Arbeit stehende Hypothese mit hoher      Wahrscheinlichkeit korrekt ist. Aber das ist ein Fehlschluss.Es hat sich in der Wissenschaft eingebÃ¼rgert, ein Ergebnis als signifikant zu bezeichnen, wenn die Wahrscheinlichkeit, dass es nur durch Zufall zustande gekommen ist, kleiner als fÃ¼nf Prozent ist â im wissenschaftlichen Jargon: ""p < 0,05"". Nehmen wir an, beim GlÃ¼cksspiel in einer dunklen Spelunke gibt Ihnen jemand einen WÃ¼rfel, und Sie mutmaÃen, dass dieser WÃ¼rfel gezinkt sein kÃ¶nnte. Konkret: dass er fast immer eine Eins wÃ¼rfelt und Sie verlieren lÃ¤sst. Sie testen diese Vermutung nun gegen die sogenannte ""Nullhypothese"", die lautet in diesem Fall: Der WÃ¼rfel ist ein ganz normaler WÃ¼rfel, die Zahlen von Eins bis Sechs erscheinen mit derselben Wahrscheinlichkeit von einem Sechstel.Anzeige				Sie wÃ¼rfeln einmal: Es erscheint eine Eins. Sie wÃ¼rfeln noch einmal â wieder eine Eins. Die Wahrscheinlichkeit, mit einem fairen WÃ¼rfel zweimal hintereinander eine Eins zu wÃ¼rfeln, betrÃ¤gt ein SechsunddreiÃigstel, also etwa 2,8 Prozent. Das Ergebnis ist also ohne Zweifel signifikant, ""p < 0,03"" wÃ¼rde ein Forscher sagen, und viele neigen tatsÃ¤chlich dazu, an dieser Stelle das Experimentieren einzustellen und die Arbeit bei einem renommierten Journal einzureichen. Denn, so folgern sie, damit ist ja die Hypothese mit Ã¼ber 97-prozentiger Wahrscheinlichkeit wahr!        Doch das ist ein Denkfehler. Um die Aussagekraft eines Ergebnisses beurteilen zu kÃ¶nnen, reicht die Signifikanz alleine nicht aus. HÃ¤tten Sie den WÃ¼rfel in einem seriÃ¶sen GeschÃ¤ft gekauft, wÃ¼rden Sie trotz der beiden Einsen nicht ernsthaft glauben, einen betrÃ¼gerischen WÃ¼rfel erworben zu haben. Wie sehr man ein signifikantes Ergebnis als Zeichen fÃ¼r die Wahrheit der Hypothese deutet, sollte also davon abhÃ¤ngen, fÃ¼r wie wahrscheinlich man die Hypothese        vor        dem Versuch gehalten hat.      Forschung in der KriseIm GeschÃ¤ft der Erkenntnisgewinnung lÃ¤uft zu viel schief. Das grÃ¶Ãte Problem sind dabei nicht etwa Plagiatoren und bewusste DatenfÃ¤lschung, sondern das GrundgerÃ¼st der Forschung selbst. Es ist ein offenes Geheimnis, dass viele Erkenntnisse der Wissenschaft nicht so gesichert sind, wie viele meinen. Auf viele Ergebnisse ist zu wenig Verlass, falsche Daten hÃ¤ufen sich und die Kontrollmechanismen sind lÃ¼ckenhaft. In ihrer ersten Ausgabe im Jahr 2014 fordern Forscher in der ZEIT deshalb: Rettet die Wissenschaft!Die Texte des Schwerpunkts:UnabhÃ¤ngige Forschung: Forscher, wehrt euch!Infografik: Wissenschaftliches Arbeiten â Der Weg zum RuhmVideo: Rettet die Wissenschaft!Statistik in der Forschung:Signifikanter UnsinnWissenschaftspolitik: ""Die Wissenschaft muss alles tun, um Schlamperei zu verhindern""Die Statistiker haben sich lange dagegen gewehrt, solche Ãberlegungen in ihre Berechnungen einzubeziehen, weil ihnen etwas Subjektives anhaftet: Wie kann meine Vor-EinschÃ¤tzung einer Hypothese      in die Berechnung ihrer Korrektheit einflieÃen? In den vergangenen Jahren aber hat sich die Ãberzeugung durchgesetzt, dass ohne eine solche Annahme Ã¼berhaupt nicht abzuschÃ¤tzen ist, inwieweit ein signifikantes Testergebnis eine Hypothese bestÃ¤tigt. Es macht zum Beispiel einen Unterschied, ob 10 oder 50 Prozent der Substanzen, die man auf eine Wirkung untersucht, eine Wirkung versprechen. Berechnet werden diese Wahrscheinlichkeiten mit der sogenannten Bayesschen Statistik, die von dem englischen Pfarrer Thomas Bayes im 18. Jahrhundert entwickelt wurde und in der Mathematik lange ein Schattendasein fÃ¼hrte. Grob gesprochen, laufen ihre Formeln darauf hinaus, dass auÃerordentliche Behauptungen auch auÃerordentlich signifikante Ergebnisse verlangen, soll man sie fÃ¼r plausibel halten.Wissenschaftliches ArbeitenUm die Infografik anzuzeigen, klicken Sie bitte auf das BildÂ Â |Â Â Â© Drushba Pankow/Bernd EberhartWie erhÃ¶ht man die Signifikanz von Experimenten? Eigentlich ganz einfach: Man wiederholt sie. Nach zwei Einsen hÃ¤lt man einen WÃ¼rfel vielleicht noch nicht fÃ¼r gezinkt, aber nach vier Einsen hintereinander glaubt kaum noch jemand, dass es hier mit rechten Dingen zugeht. Der Signifikanzwert verbessert sich von 2,8 auf 0,08 Prozent. Aber die reine Reproduktion bereits verÃ¶ffentlichter Experimente trÃ¤gt einem Wissenschaftler kaum Lorbeeren ein.Auch die Medien tragen dazu bei, dass zweifelhafte Ergebnisse verÃ¶ffentlicht werden. Forschung bekommt umso mehr Aufmerksamkeit, je Ã¼berraschender das Ergebnis ist. Die Zeitungen lieben Geschichten, die anfangen mit ""anders, als die Wissenschaft seit Jahrhunderten glaubte ..."". Aber was die Wissenschaft seit Jahrhunderten glaubt, ist meist auch gut durch Experimente abgesichert â und kann eigentlich durch eine einzige Arbeit nicht erschÃ¼ttert werden, sei sie noch so signifikant. Schlagzeilen macht sie trotzdem.Anmerkung des Autors: Das Beispiel mit den beiden WÃ¼rfeln, mit dem ich den Begriff der Signifikanz griffig verdeutlichen wollte, ist leider falsch gewÃ¤hlt und auch falsch berechnet worden. Dadurch, dass die Hypothese ""Der WÃ¼rfel ist gezinkt"" selbst eine Wahrscheinlichkeitsaussage ist (nÃ¤mlich, dass der WÃ¼rfel Ã¼berdurchschnittlich oft eine Eins zeigt), wird die Berechnung der Signifikanz erheblich komplizierter, als sie hier dargestellt ist. Das vermeintlich simple Beispiel ist also ein unnÃ¶tig kompliziertes. Die allgemeine Aussage des Textes wird davon aber nicht beeintrÃ¤chtigt.Zur StartseiteÂ "
