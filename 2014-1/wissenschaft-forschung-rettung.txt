"","x"
"1","UnabhÃ¤ngige Forschung: Rettet die Wissenschaft!Im GeschÃ¤ft der Erkenntnisgewinnung lÃ¤uft zu viel schief. Zum GlÃ¼ck gibt es Menschen, die das Ã¤ndern wollen. vonÂ Stefan Schmitt und Stefanie Schramm											DIE ZEIT NÂº 01/2014 2. Januar 2014Â 									12:14 UhrÂ 							100 KommentareOhne Antibiotika und Mikroelektronik, ohne Pflanzenzucht, Blinddarmoperationen oder Solarzellen. Ohne diese und zahllose andere Errungenschaften menschlicher Neugier sÃ¤he das Leben ganz anders aus. Wir wÃ¤ren hungriger, krÃ¤nker, ignoranter, die meisten von uns wÃ¤ren vermutlich schon tot â oder nie geboren worden.Dabei fuÃen die Erfolge der modernen Forschung auf simplen Prinzipien: auf systematischem ErgrÃ¼nden und skeptischem Hinterfragen. Irgendwann in der frÃ¼hen Neuzeit hatte sich diese kritische Geisteshaltung als jene herauskristallisiert, die zu verlÃ¤sslichen Aussagen Ã¼ber die Welt fÃ¼hrt. Doch ausgerechnet heute, da wir die FrÃ¼chte jahrzehnte-, ja jahrhundertelangen Forschens ernten, in einer Zeit, in der alle Lebensbereiche von der Wissenschaft durchdrungen zu sein scheinen, ausgerechnet jetzt wird das Vertrauen in die erfolgreiche Erkenntnismaschinerie schwer erschÃ¼ttert.Anzeige				        Gerade hat der frisch geehrte Physik-NobelpreistrÃ¤ger Peter Higgs gesagt, heute wÃ¼rde er an keiner UniversitÃ¤t mehr einen Job bekommen, da von jungen Forschern erwartet werde, ""einen Aufsatz nach dem anderen rauszuhauen"". Parallel zÃ¼rnte der diesjÃ¤hrige Nobel-Laureat fÃ¼r Medizin, Randy Schekman, den fÃ¼hrenden Fachzeitschriften        Nature        und        Science. Er warf ihnen ""Verzerrung"" und ""Tyrannei"" vor, weil sie statt Relevanz ""sexy Themen"" und ""steile Thesen"" bevorzugten; damit kÃ¶nnten sie ""Forscher dazu verleiten, zu pfuschen"" â mit den beiden altehrwÃ¼rdigen Institutionen griff er zwei tragende SÃ¤ulen des Systems an. Und der Starpsychologe Daniel Kahneman, ebenfalls NobelpreistrÃ¤ger, warnte im FrÃ¼hjahr, dass die gesamte Fachrichtung der Sozialpsychologie ""gegen die Wand fahren"" werde, nachdem sich eine Reihe von Ergebnissen aus wichtigen Studien des Feldes nicht bestÃ¤tigen lieÃen.              TatsÃ¤chlich hÃ¤ufen sich die Meldungen, die nicht in das Idealbild der Wissenschaft passen: Fachzeitschriften ziehen heute 15-mal so viele fragwÃ¼rdige Artikel zurÃ¼ck wie noch vor zehn Jahren. Als die Biotechfirma Amgen mehr als 50 wichtige Krebsstudien wiederholte, bestÃ¤tigten sich deren Resultate nur in zehn Prozent der FÃ¤lle. Das heiÃt, neun von zehn vermeintlich sicheren Erkenntnissen der Wissenschaft waren gar keine. Forschung in der KriseIm GeschÃ¤ft der Erkenntnisgewinnung lÃ¤uft zu viel schief. Das grÃ¶Ãte Problem sind dabei nicht etwa Plagiatoren und bewusste DatenfÃ¤lschung, sondern das GrundgerÃ¼st der Forschung selbst. Es ist ein offenes Geheimnis, dass viele Erkenntnisse der Wissenschaft nicht so gesichert sind, wie viele meinen. Auf viele Ergebnisse ist zu wenig Verlass, falsche Daten hÃ¤ufen sich und die Kontrollmechanismen sind lÃ¼ckenhaft. In ihrer ersten Ausgabe im Jahr 2014 fordern Forscher in der ZEIT deshalb: Rettet die Wissenschaft!Die Texte des Schwerpunkts:UnabhÃ¤ngige Forschung: Forscher, wehrt euch!Infografik: Wissenschaftliches Arbeiten â Der Weg zum RuhmVideo: Rettet die Wissenschaft!Statistik in der Forschung:Signifikanter UnsinnWissenschaftspolitik: ""Die Wissenschaft muss alles tun, um Schlamperei zu verhindern""Ãhnlich erging es dem Pharmaunternehmen Bayer, wo sich laut einer internen Umfrage in gerade mal einem Viertel der einbezogenen 67 Projekte die jeweils relevanten VerÃ¶ffentlichungen erfolgreich replizieren lieÃen. Verlassen kann man sich also auf viel weniger, als man meint.      Daran sind nicht nur FÃ¤lscher und Plagiatoren schuld, Ã¼ber die in den letzten Jahren so viel zu lesen war. Einzelne mÃ¶gen bÃ¶swillig betrÃ¼gen, gravierender aber fÃ¼r die QualitÃ¤t der Wissenschaft insgesamt sind Fehler im System. Die erscheinen zunÃ¤chst vielleicht harmlos, wirken aber verhÃ¤ngnisvoll.        Denn gleichzeitig wÃ¤chst die Menge der Forschungsergebnisse rasant: Weltweit arbeiten heute rund sieben Millionen Wissenschaftler. Sie versuchen, ihre Resultate in mehr als 30.000 Fachzeitschriften zu verÃ¶ffentlichen. In einem einzigen Jahr erscheinen nach ZÃ¤hlung von        Nature        1,4 Millionen FachaufsÃ¤tze â das sind Tag fÃ¼r Tag 3850 StÃ¼ck. Selbst in ihrem eigenen Fachgebiet kÃ¶nnen Spezialisten kaum noch die Literatur Ã¼berblicken und beurteilen, was davon wirklich etwas taugt. In dieser Lage kÃ¶nnen schwarze Schafe, blinde Flecken und SchlupflÃ¶cher die gesamte Wissenschaft in Misskredit bringen. Sollten sie Ã¼berhandnehmen, es wÃ¤re ein Schaden fÃ¼r alle, mit Folgen fÃ¼r jeden.      Abhilfe ist dringend nÃ¶tig. Junge Forscher versuchen, die Schwachstellen auszubessern: als Aufdecker, Fallensteller, Replikateure, FehlerjÃ¤ger, Negativpublizisten und Reformatoren.UnabhÃ¤ngige Forschung: Rettet die Wissenschaft!Seite 2/4: 								Die Aufdecker und die FallenstellerDie Aufdecker        Als bekanntestes Selbstreinigungsmittel der Wissenschaft gilt der Widerruf fehlerhafter Artikel. BloÃ setzen es die Fachjournale am liebsten so unauffÃ¤llig wie nur irgend mÃ¶glich ein. AuÃer in ein paar SkandalfÃ¤llen verschwinden Widerrufe praktisch spurlos in den Archiven, die Originalartikel dagegen werden munter weiter zitiert. ""Viele Leute haben Ã¼berhaupt keine Ahnung, wie viele Artikel zurÃ¼ckgezogen werden, selbst Wissenschaftler nicht"", sagt Adam Marcus. Deshalb hat er vor vier Jahren zusammen mit Ivan Oransky das Blog        Retraction Watch        gestartet. 15.000-mal am Tag wird es angeklickt, mehr als tausend Widerrufe haben sie schon Ã¶ffentlich gemacht.      Die beiden Wissenschaftsjournalisten recherchieren, warum ein Artikel zurÃ¼ckgezogen wurde. Denn oft sind die Angaben der Zeitschriften Ã¤uÃert dÃ¼rftig. ""Der Artikel wurde vom Autor zurÃ¼ckgezogen"", zitiert Marcus seine Lieblingsphrase, ""sehr hilfreich!"". Nicht immer erhÃ¤lt er auf Nachfrage erhellendere Antworten. Ein Herausgeber habe schlicht gesagt: ""Das geht Sie, verdammt noch mal, nichts an.""Das muss sich Ã¤ndernDie UmstÃ¤nde sind schuld? Falsche Anreize? Nicht nur! 9 dringende Forderungen fÃ¼r eine bessere Forschung:1. Besser als VertrauenForschungsergebnisse mÃ¼ssen viel hÃ¤ufiger durch Wiederholung nachgeprÃ¼ft werden (Â»repliziertÂ«), dafÃ¼r sollten Gelder reserviert werden â und Seiten in den Fachzeitschriften.2. QualitÃ¤t vor QuantitÃ¤tDie schiere Menge der VerÃ¶ffentlichungen eines Forschers darf kein MaÃ fÃ¼r seine Leistung sein.3. Misserfolge wÃ¼rdigenAuch Negativ- und Nullergebnisse gehÃ¶ren publiziert.4. AnonymitÃ¤t wahrenWhistleblower mÃ¼ssen besser vor Enttarnung geschÃ¼tzt werden.5. Studien registrierenDamit nachtrÃ¤glich nicht daran gedreht werden kann, mÃ¼ssen Hypothese, Vorgehen und Ziel eines Experiments schon vorher protokolliert werden.6. Konsequent offenlegenAlle Forschungsdaten zu einer Publikation mÃ¼ssen zugÃ¤nglich sein.7. Statistik lebenAuswertung muss zum zentralen Bestandteil jeder Wissenschaftlerausbildung werden.8. Skepsis vernetzenDie Expertise jedes Einzelnen muss genutzt werden, um Paper zu bewerten â und auch die Arbeit der Gutachter.9. Nachmacher eindÃ¤mmenWer klar nachklappert (Â»Me-too-ForschungÂ«), obwohl die Wissenschaft schon weiter ist, sollte weder gefÃ¶rdert noch publiziert werden.FÃ¼r fast 30 Prozent aller Widerrufe sind Fehler der Grund, fÃ¼r weitere zehn Prozent nicht reproduzierbare Ergebnisse, fÃ¼r den Rest ist es grÃ¶Ãtenteils wissenschaftliches Fehlverhalten. Doch in vielen weiteren Artikeln dÃ¼rften unentdeckte Makel stecken. Eine Ursache dafÃ¼r sind mangelhafte Statistikkenntnisse. Es ist paradox: Die Bedeutung statistischer Analysen und der Signifikanz als GÃ¼tekriterium ist so groÃ wie nie â doch die statistischen FÃ¤higkeiten vieler Forscher sind so mÃ¤Ãig wie eh und je. ""Da hat sich in den vergangenen 15 Jahren nicht viel getan"", sagt Hans-Hermann Dubben vom UniversitÃ¤tsklinikum Hamburg-Eppendorf, der angehenden Medizinern das statistische Handwerkszeug beibringt und nebenbei AnalyseschwÃ¤chen in wissenschaftlichen Studien aufspÃ¼rt.Die Journale wiederum schÃ¼tzen mit ihrer diskreten Widerrufpolitik nicht nur den eigenen Ruf, sondern auch einen Mythos: den des wissenschaftlichen Fachaufsatzes (im Forscherjargon: ""Paper"") als Instanz untrÃ¼glicher Wahrheit, als solider Baustein im endlosen Turmbau des Wissens. Beitrag fÃ¼r Beitrag rÃ¼cken Marcus und Oransky dieses Bild zurecht: ""Wir wollen das Paper entmystifizieren.""Die Fallensteller        Der Ruf des Papers brÃ¶ckelt nicht zuletzt deshalb, weil die QualitÃ¤tskontrolle der Fachzeitschriften, das ""Peer-Review"", alles andere als unfehlbar ist. Bei guten Journalen begutachten die besten Experten des Fachs anonym die eingesandten Erkenntnisse, doch auch ihnen entgehen viele Fehler. Wie viele es tatsÃ¤chlich sind, das muss den meisten erst noch vor Augen gefÃ¼hrt werden. Unter jungen Wissenschaftlern hat sich ein regelrechter Trendsport etabliert, das        hoaxing,        benannt nach dem englischen Wort fÃ¼r Jux: Man bastele ein vÃ¶llig unsinniges Manuskript, reiche es bei einer Zeitschrift ein und warte ab. VerÃ¶ffentlicht das Journal den Artikel, ist der SpaÃ groÃ, die Zeitschrift und seine Gutachter sind blamiert.      Wissenschaftliches ArbeitenUm die Infografik anzuzeigen, klicken Sie bitte auf das BildÂ Â |Â Â Â© Drushba Pankow/Bernd Eberhart        Vorbild der Hoaxer ist der Physiker Alan Sokal, der 1996 die sozialwissenschaftliche Zeitschrift        Social Text        mit einem Artikel bloÃstellte, in dem er die Quantengravitation als soziales Konstrukt interpretierte. Weitere Hoaxes: Drei serbische Studenten reichten ein Paper bei        Metalurgia International        ein, das Michael Jackson, die Satirefigur Borat und einen Pornostar zitiert. Es wurde als interessant und wissenschaftlich seriÃ¶s akzeptiert. Ein gewisser Professor Rathke schickte computerfabrizierten Nonsens an        Advances in Pure Mathematics.        Er wurde akzeptiert. Ein Autorenteam des fiktiven Center for Research in Applied Phrenology (kurz CRAP, Englisch fÃ¼r Mist) reichte ein ebensolches Paper bei        The Open Information Science Journal        ein. Es wurde akzeptiert. Als die Sache aufflog, trat der Herausgeber zurÃ¼ck. Zuletzt akzeptierten im vergangenen Herbst mehr als 150 Zeitschriften ein Manuskript des Biologen John Bohannon Ã¼ber ein Krebsmittel. Es war erkennbar fingiert, doch offenbar hatte kein Gutachter etwas bemerkt.              Immer wieder wird das Peer-Review mit dem Verweis auf Winston Churchill verteidigt. Der britische Premierminister hatte einst die Demokratie als die ""schlechteste aller Staatsformen"" bezeichnet â abgesehen von all den anderen Formen, die ausprobiert worden seien. Peer-Review als am wenigsten schlechte Variante der QualitÃ¤tssicherung? Selbst gegen Unsinn mit Ansage ist es nicht gefeit: Als die Herausgeberin des renommierten        British Medical Journal        ihre eigenen Gutachter mit einem fehlergespickten Artikel testete, fanden diese â trotz Vorwarnung â durchschnittlich nur weniger als jeden vierten Fehler. Der Mathematiker Ulrich Berger nennt die Gutachter ""TeilzeitputzmÃ¤nner und -frauen""; sie sollen die Selbstreinigungskraft der Wissenschaft gewÃ¤hrleisten, aber bitte ohne Honorar und meist nach Feierabend â wen wundert es, wenn das Ergebnis da oft nicht streifenfrei ist?      UnabhÃ¤ngige Forschung: Rettet die Wissenschaft!Seite 3/4: 								Die Replikateure und die FehlerjÃ¤gerDie Replikateure        Viele Ungereimtheiten lassen sich allerdings gar nicht am Schreibtisch aufdecken, sondern nur im Labor. Die Wiederholung von Experimenten (""Replikation"") ist die wissenschaftliche Feuerprobe. Eine solche haben Frank Renkewitz und seine Kollegin Stephanie MÃ¼ller unternommen; anfangs waren sie ganz zuversichtlich. Drei Psychologen hatten getestet, wie WÃ¶rter die Aufmerksamkeit im Raum lenken. (Wenn man auf einem Monitor ""Cowboyhut"" statt ""Stiefel"" liest, wie nimmt man dann weitere Reize auf dem Bildschirm wahr?) Das Resultat war in        Psychological Science        verÃ¶ffentlicht worden. ""Interessante Untersuchung"", habe er gedacht, sagt Renkewitz, ""kann schon stimmen."" Als Erstes forderte Renkewitz die Autoren auf, ihm ihre Versuchsprotokolle zu schicken.              Der Psychologe von der UniversitÃ¤t Erfurt gehÃ¶rt zum ""Reproducibility Project"": Mehr als hundert Studien aus drei der angesehensten Fachzeitschriften der Disziplin will die Initiative wiederholen. Der amerikanische Psychologe Brian Nosek hatte die Idee dazu gehabt, nachdem sich einige klassische Ergebnisse aus der Sozialpsychologie einfach nicht hatten replizieren lassen        (ZEIT        Nr. 22/13). ""Fast jeder, der lÃ¤nger als fÃ¼nf Jahre dabei ist, hat schon einmal erlebt, dass sich ein Ergebnis nicht wiederholen lÃ¤sst"", sagt Renkewitz. Doch kaum jemand mache das Ã¶ffentlich, weil reine Replikation kein Prestige bringe, hÃ¶chstens Ãrger. Die Konsequenz: ""Das Vertrauen darin, dass sich die Wissenschaft selbst korrigiert, ist exzessiv ungerechtfertigt.""      Anzeige				Im Protokoll seiner drei Kollegen stieÃ Renkewitz auf eine erste Ungereimtheit: Vor dem Experiment hatten sie allem Anschein nach genau das entgegengesetzte Ergebnis erwartet. ""Offenbar haben sie die verÃ¶ffentlichte Hypothese erst nach dem Versuch aufgestellt."" Renkewitz kommentiert trocken: ""Das hat meine Zuversicht gemindert.""Im FrÃ¼hjahr 2014 wird das Reproducibility Project zum ersten Mal eine Zahl verÃ¶ffentlichen, vor der sich viele fÃ¼rchten â die aktuelle Replikationsquote: Welcher Anteil an den Studien konnte bislang bestÃ¤tigt werden? Den Versuch der drei Psychologen hat Renkewitz schlieÃlich Schritt fÃ¼r Schritt wiederholt. Und fand dabei Ã¼berhaupt keinen Effekt, weder in die eine noch in die andere Richtung â Replikation fehlgeschlagen. Bei zwei anderen Studien gelang es ihm, seine persÃ¶nliche Replikationsquote lautet also: zwei Drittel.Wissenschaftler sind ja typischerweise ebenso Autoren wie Gutachter, einige zusÃ¤tzlich noch Redakteure. Das heiÃt, innerhalb eines Fachs sind wir immer Spieler und Schiedsrichter zugleich.JÃ¶rn BullerdiekDie FehlerjÃ¤ger        Wie viele weitere, lÃ¤ngst verÃ¶ffentlichte Paper stecken noch voller Fehler? FÃ¼r die Suche sind Instinkt und HartnÃ¤ckigkeit nÃ¶tig. Das zeigt niemand besser als Clare Francis, wie die wohl bekannteste Unbekannte der Szene sich nennt. ""Sie hat Hunderte E-Mails an Redakteure von lebenswissenschaftlichen Fachzeitschriften geschickt und auf FÃ¤lle von Plagiaten oder Manipulationen hingewiesen"", wÃ¼rdigte        Nature        sie Ende November und schrieb, bereits ""eine Handvoll"" korrigierter oder zurÃ¼ckgezogener AufsÃ¤tze seien auf Francisâ Konto gegangen.      Vor gut einem Jahr erhielt auch der Bremer Krebsforscher JÃ¶rn Bullerdiek Post von Francis: Bei einem italienischen Kollegen stimme etwas nicht. Er solle sich das einmal anschauen! Bullerdiek beÃ¤ugte Grafiken aus unterschiedlichen Papern des Fachkollegen, die sich irritierend Ã¤hnlich sahen. Mittlerweile sind zwei Artikel zurÃ¼ckgezogen, gegen den Hauptautor ermittelt die Staatsanwaltschaft.Solche Erfolge sind allerdings selten und die WiderstÃ¤nde oft enorm. ""Wissenschaftler sind ja typischerweise ebenso Autoren wie Gutachter, einige zusÃ¤tzlich noch Redakteure"", beschreibt Bullerdiek die Situation, ""das heiÃt, innerhalb eines Fachs sind wir immer Spieler und Schiedsrichter zugleich."" Entsprechend frustrierend ist die Arbeit fÃ¼r selbst ernannte JÃ¤ger wie Clare Francis. Per E-Mail berichtet sie von Ignoranz und Abwehrreaktionen. ""Ich bin einfach jemand, der sich die MÃ¼he macht, die Daten anzuschauen"", schreibt sie. Ihre GegenÃ¼ber bedrÃ¤ngt sie, dasselbe zu tun. FÃ¼r viele Fachjournale ist sie deswegen ein rotes Tuch. Fehlersuche verspricht nur MÃ¼he und HÃ¤ndel.        Daher agieren die JÃ¤ger hÃ¤ufig anonym. Das lÃ¤sst sich auch bei der Website PubPeer beobachten: Seit Oktober 2012 kann dort jedermann auf die SchwÃ¤chen in AufsÃ¤tzen hinweisen. WÃ¤hrend die Macher der Seite selbst im Verborgenen bleiben, zeitigen die zumeist anonym gefÃ¼hrten Diskussionen auf PubPeer Ã¶ffentliche Konsequenzen. Zum Beispiel musste die FachzeitschriftCell        im vergangenen FrÃ¼hsommer eine viel beachtete Studie des Klonforschers Shoukhrat Mitalipov korrigieren, nachdem PubPeer-Nutzer darin Schlampereien aufgedeckt hatten. So schÃ¤rfen die FehlerjÃ¤ger das Bewusstsein â bei Autoren wie Gutachtern. JÃ¶rn Bullerdiek berichtet nach seinen Erfahrungen mit Francis: ""Bei Begutachtungen schaue ich inzwischen ganz anders hin.""      UnabhÃ¤ngige Forschung: Rettet die Wissenschaft!Seite 4/4: 								Die Negativpublizisten und die ReformatorenDie NegativpublizistenSelbst wenn Paper zweifelsfrei stimmen, verzerren sie in der Summe die Wirklichkeit â weil viele korrekte Studienergebnisse unter den Tisch fallen. Es sind Resultate fehlgeschlagener oder ergebnisloser Experimente.JUnQ soll das Ã¤ndern, eine hÃ¶chst ungewÃ¶hnliche Fachzeitschrift. Ersonnen wurde sie auf einem Workshop von Nachwuchsforschern, beheimatet ist sie an der UniversitÃ¤t Mainz. Ihr Titel ist kokett, klingt wie junk, englisch fÃ¼r MÃ¼ll, steht aber fÃ¼r Journal of Unsolved Questions â ""Zeitschrift fÃ¼r ungelÃ¶ste Fragen"".Â© Screenshot/ZEIT ONLINEDas Titelthema der Januarausgabe von        JUnQ        , ""QualitÃ¤t in der Wissenschaft"", passt zur Mission des Teams. Der Chemiker Andreas Neidlinger beschreibt sie so: ""Wir mÃ¶chten Forschungsarbeiten Ã¶ffentlich machen, die sonst in der Schublade verschwinden wÃ¼rden."" Verschwinden, weil ein Experiment nicht zum gewÃ¼nschten Resultat gefÃ¼hrt hat â Negativergebnisse haben bei Fachzeitschriften kaum Chancen. Gleichzeitig gilt fÃ¼r junge Forscher:        publish or perish!        Wer nicht verÃ¶ffentlicht, kann seine Karriere vergessen. So werden Ã¼berwiegend positive Befunde eingereicht, von Studien, bei denen herauskam, was der Autor erwartet hatte. Seit 1990 hat sich der Anteil von VerÃ¶ffentlichungen mit Negativergebnissen halbiert. ""Dass etwas nicht funktioniert, ist aber fÃ¼r den wissenschaftlichen Erkenntnisgewinn genauso wichtig"", findet Neidlinger.              Offenbar hat        JUnQ        damit einen Nerv getroffen. Im Jahr 2012 erhielt das Team den Deutschen Ideenpreis, mit der aktuellen Ausgabe geht es schon in den vierten Jahrgang. Andererseits steckt in neuen Heft nur ein einziger Forschungsartikel. ""Ãber ein gescheitertes Projekt zu schreiben ist nicht weniger Arbeit als ein gewÃ¶hnlicher Artikel"", erklÃ¤rt Neidlinger. HÃ¤ufig erleben die        JUnQ-        Macher, dass Forscher zwar Manuskripte einreichen, bei den Nachfragen der Gutachter dann aber die Lust verlieren. Auch das ungewÃ¶hnliche Journal spÃ¼rt die gewohnten Denkmuster: Was die Karriere nicht voranbringt, verdient auch keinen Aufwand.      Die ReformatorenDass sich etwas Ã¤ndern muss, haben inzwischen auch Institutionen erkannt: GroÃe Fachverlage machen mit einem Projekt (""Crossmark"") Korrekturen und Widerrufe von Artikeln auffindbar. Die Deutsche Forschungsgemeinschaft betont als Kriterium zur Mittelvergabe die QualitÃ¤t von VerÃ¶ffentlichungen, nicht mehr nur ihre Anzahl. Mehrere groÃe Replikationsprojekte sind gestartet. Die wunden Punkte der Wissenschaft, das zeigen die Beispiele von den Aufdeckern Ã¼ber die Fallensteller bis zu den FehlerjÃ¤gern, kÃ¶nnen aber nicht geheilt werden, solange nicht der wissenschaftliche Prozess insgesamt reformiert wird. Wie will man kÃ¼nftigen Forschern garantieren, dass sie auf echte Befunde aufbauen?        ""Ich befÃ¼rworte das heutige System des Peer-Reviews                zwar, aber ich denke, dass es ergÃ¤nzt werden kÃ¶nnte"", formuliert Diana Deca vorsichtig. Als Neurowissenschaftlerin promoviert sie an der TU MÃ¼nchen, als studierte Wissenschaftsphilosophin denkt sie Ã¼ber genau diese ErgÃ¤nzung fÃ¼r das Peer-Review nach. Gemeinsam mit einem Kollegen sammelt sie seit vier Jahren Ideen ein, quer durch die        scientific community        . ""Wir haben ziemlich viele Ãbereinstimmung vorgefunden"", sagt Deca. Die Schnittmenge der Visionen: Gutachter sollen nicht lÃ¤nger anonym sein, ihre Arbeit soll Ã¶ffentlich bewertet werden. Vor allem soll die Begutachtung eines Aufsatzes auch Ã¼ber dessen Publikation hinaus andauern, sodass weitere Experten und jeder Leser die GÃ¼te beurteilen kÃ¶nnen. Alle Reviews wÃ¤ren ebenfalls Ã¶ffentlich â und bewertbar.        Open evaluation        heiÃt das. Mehr ""Tempo, Kontrolle und Transparenz"" verspricht Deca sich davon. ""AuÃerdem kommen mehr Menschen und neue Bewertungsformen ins Spiel.""              Dass solche Ideen funktionieren kÃ¶nnen, zeigt das Beispiel arxiv.org. Auf diesen Server laden vor allem Physiker, Mathematiker und Informatiker ihre neuesten Manuskripte        (""preprint"")        hoch, derzeit rund 8000 AufsÃ¤tze pro Monat. Informelles Gegenlesen fÃ¼hrt dazu, dass manche AufsÃ¤tze erst gar nicht zu einer Fachzeitschrift geschickt werden, viele andere werden dank Hinweisen der arxiv-Nutzer spÃ¤ter in einer verbesserten Fassung abgedruckt. Und im Jahr 2006 wurde erstmals fÃ¼r einen ausschlieÃlich auf arxiv verÃ¶ffentlichten Aufsatz die Fields-Medaille verliehen â fÃ¼r Mathematiker das Ãquivalent des Nobelpreises. Gerade wird der Nutzerkreis auf Biologen ausgeweitet.      Einzelne Komponenten fÃ¼r ein kÃ¼nftiges Modell existieren also bereits.FazitAn den unterschiedlichsten Stellen suchen Forscher schon nach LÃ¶sungen, sie investieren MÃ¼he und (Frei-)Zeit, probieren neue Ideen aus. Jetzt muss aus den einzelnen Initiativen ein ernsthafter Umbau werden. Klar ist, die QualitÃ¤tskontrolle gehÃ¶rt auf viel mehr Schultern verteilt als bisher, der gesamte Prozess muss transparenter sein. Allein die schiere Masse an Forschern und Ergebnissen macht das nÃ¶tig â und die digitale Vernetzung macht es mÃ¶glich. Damit der Umbau funktioniert, mÃ¼ssen die Anreize und der Rahmen stimmen: Eine von mehreren zentralen Forderungen (siehe Kasten oben) lautet, dass Forschungsergebnisse wieder hÃ¤ufiger durch Wiederholung nachgeprÃ¼ft werden sollen. Damit das kein frommer Wunsch bleibt, mÃ¼ssen bei der Planung kÃ¼nftiger Forschungsprogramme von vornherein eigene Budgets fÃ¼r die Replikation vorgesehen werden. Es geht um nicht weniger als eine neue Forschungsarchitektur.ZustÃ¤ndig fÃ¼r deren Entwurf sind nicht in erster Linie Forschungspolitiker, sondern die Forscher selbst. Nicht nur weil sie das jetzige System am besten kennen. Sondern weil es ihr Job ist, Probleme zu lÃ¶sen und Neues zu entdecken. So gesehen, waren die Chancen, einen neuen Rahmen fÃ¼r die menschliche Neugier zu erfinden, nie besser als heute: Sieben Millionen Wissenschaftlern sollte da doch etwas einfallen.Diesen Artikel finden Sie als Audiodatei im Premiumbereich unter www.zeit.de/audioZur StartseiteÂ "
